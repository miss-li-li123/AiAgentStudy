{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"deepseek.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "api_base = os.getenv(\"DEEPSEEK_API_BASE\")\n",
    "serp_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base\n",
    "os.environ[\"SERPAPI_API_KEY\"] =serp_api_key\n",
    "# ä¸º DeepSeek é…ç½®ï¼ˆå¯é€‰ï¼‰\n",
    "DEEPSEEK_CONFIG = {\n",
    "    #\"model\": \"gpt-3.5-turbo\",  # æˆ–è€…ä½¿ç”¨ DeepSeek å…¼å®¹æ¨¡å‹\n",
    "    #\"openai_api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    # å¦‚æœä½¿ç”¨ DeepSeek:\n",
    "    \"model\": \"deepseek-chat\",\n",
    "    \"openai_api_base\": os.environ[\"DEEPSEEK_API_BASE\"],\n",
    "    \"openai_api_key\": os.environ[\"DEEPSEEK_API_KEY\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¦‚ä½•ç»™agentæ­£ç¡®çš„å¢åŠ è®°å¿†\n",
    "\n",
    "- å°†memoryæ’å…¥åˆ°æç¤ºè¯æ¨¡æ¿ä¸­\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.prompts import  MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰å¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/1534123048.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm=ChatOpenAI(\n",
    "    temperature=0,\n",
    "    **DEEPSEEK_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ„å»ºagentå¯ç”¨å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='Search', description='useful for when you need to answer questions about current events or the current state of the world', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='54593553f44d1d9c8c2e610beaf57d8de0fe6c25fce97628e591ef64f5ddad04', aiosession=None)>), Tool(name='Calculator', description='useful for when you need to answer questions about math', func=<bound method Chain.run of LLMMathChain(verbose=True, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x136a31850>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1374aa9f0>, model_name='deepseek-chat', temperature=0.0, model_kwargs={}, openai_api_key='sk-1719a446a8a643d8ba71d7b4cee55069', openai_api_base='https://api.deepseek.com/v1', openai_proxy=''), output_parser=StrOutputParser(), llm_kwargs={}), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x136a31850>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1374aa9f0>, model_name='deepseek-chat', temperature=0.0, model_kwargs={}, openai_api_key='sk-1719a446a8a643d8ba71d7b4cee55069', openai_api_base='https://api.deepseek.com/v1', openai_proxy=''))>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/3294897194.py:4: LangChainDeprecationWarning: This class is deprecated and will be removed in langchain 1.0. See API reference for replacement: https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_math.base.LLMMathChain.html\n",
      "  llm_math_chain = LLMMathChain(\n",
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/3294897194.py:4: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  llm_math_chain = LLMMathChain(\n"
     ]
    }
   ],
   "source": [
    "#æ„å»ºä¸€ä¸ªæœç´¢å·¥å…·\n",
    "search = SerpAPIWrapper()\n",
    "#åˆ›å»ºä¸€ä¸ªæ•°å­¦è®¡ç®—å·¥å…·\n",
    "llm_math_chain = LLMMathChain(\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events or the current state of the world\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "]\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¢åŠ memoryç»„ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/1205651814.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "#è®°å¿†ç»„ä»¶\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/1161536941.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_chain = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.OPENAI_FUNCTIONS, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True,#å¤„ç†è§£æé”™è¯¯\n",
    "    memory=memory #è®°å¿†ç»„ä»¶\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹é»˜è®¤çš„agents promptæ˜¯ä»€ä¹ˆæ ·çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI assistant.', additional_kwargs={}, response_metadata={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "content='You are a helpful AI assistant.' additional_kwargs={} response_metadata={}\n",
      "prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}') additional_kwargs={}\n",
      "variable_name='agent_scratchpad'\n"
     ]
    }
   ],
   "source": [
    "print(agent_chain.agent.prompt.messages)\n",
    "print(agent_chain.agent.prompt.messages[0])\n",
    "print(agent_chain.agent.prompt.messages[1])\n",
    "print(agent_chain.agent.prompt.messages[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mä½ å¥½ï¼Œææ™¨ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºä½ æä¾›æ”¯æŒã€‚ç¥ä½ ä»Šå¤©ä¸€åˆ‡é¡ºåˆ©ï¼ ğŸ˜Š\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mç›®å‰æˆ‘æ— æ³•çŸ¥é“ä½ çš„åå­—ï¼Œå› ä¸ºä½ è¿˜æ²¡æœ‰å‘Šè¯‰æˆ‘ï¼ğŸ˜Š ä½†å¦‚æœä½ æ„¿æ„å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šè®°ä½å¹¶åœ¨æ¥ä¸‹æ¥çš„å¯¹è¯ä¸­ä½¿ç”¨å®ƒã€‚æˆ–è€…ï¼Œä½ å¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘ä½ æƒ³è®©æˆ‘æ€ä¹ˆç§°å‘¼ä½ ï½ ä½ å¸Œæœ›æˆ‘æ€ä¹ˆç§°å‘¼ä½ å‘¢ï¼Ÿ\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ç›®å‰æˆ‘æ— æ³•çŸ¥é“ä½ çš„åå­—ï¼Œå› ä¸ºä½ è¿˜æ²¡æœ‰å‘Šè¯‰æˆ‘ï¼ğŸ˜Š ä½†å¦‚æœä½ æ„¿æ„å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šè®°ä½å¹¶åœ¨æ¥ä¸‹æ¥çš„å¯¹è¯ä¸­ä½¿ç”¨å®ƒã€‚æˆ–è€…ï¼Œä½ å¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘ä½ æƒ³è®©æˆ‘æ€ä¹ˆç§°å‘¼ä½ ï½ ä½ å¸Œæœ›æˆ‘æ€ä¹ˆç§°å‘¼ä½ å‘¢ï¼Ÿ'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "éœ€è¦ä½¿ç”¨agent_kwargsä¼ é€’å‚æ•°ï¼Œå°†chat_historyä¼ å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.OPENAI_FUNCTIONS, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True,#å¤„ç†è§£æé”™è¯¯\n",
    "    agent_kwargs={\n",
    "        \"extra_prompt_messages\":[MessagesPlaceholder(variable_name=\"chat_history\"),MessagesPlaceholder(variable_name=\"agent_scratchpad\")],\n",
    "    },\n",
    "    memory=memory #è®°å¿†ç»„ä»¶\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹é‡æ–°æ¸²æŸ“åçš„æç¤ºè¯æ¨¡ç‰ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI assistant.', additional_kwargs={}, response_metadata={}), MessagesPlaceholder(variable_name='chat_history'), MessagesPlaceholder(variable_name='agent_scratchpad'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "content='You are a helpful AI assistant.' additional_kwargs={} response_metadata={}\n",
      "variable_name='chat_history'\n",
      "variable_name='agent_scratchpad'\n"
     ]
    }
   ],
   "source": [
    "print(agent_chain.agent.prompt.messages)\n",
    "print(agent_chain.agent.prompt.messages[0])\n",
    "print(agent_chain.agent.prompt.messages[1])\n",
    "print(agent_chain.agent.prompt.messages[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mä½œä¸ºä¸€ä¸ªæ–‡æœ¬äº¤äº’çš„AIï¼Œæˆ‘å¯ä»¥å›é¡¾æˆ‘ä»¬çš„å¯¹è¯è®°å½•ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„å¯¹è¯å†…å®¹å¦‚ä¸‹ï¼š\n",
      "\n",
      "1. æ‚¨é—®æˆ‘ï¼šâ€œæˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿâ€\n",
      "2. æˆ‘å›ç­”è¯´ï¼Œä½œä¸ºAIï¼Œæˆ‘æ²¡æœ‰è®¿é—®æ‚¨ä¸ªäººä¿¡æ¯çš„æƒé™ï¼Œæ‰€ä»¥æˆ‘ä¸çŸ¥é“æ‚¨çš„åå­—ï¼Œå¹¶æå‡ºå¦‚æœæ‚¨æ„¿æ„å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šçŸ¥é“å¦‚ä½•ç§°å‘¼æ‚¨ã€‚\n",
      "\n",
      "è¿™å°±æ˜¯æˆ‘ä»¬ç›®å‰ä¸ºæ­¢çš„å…¨éƒ¨å¯¹è¯å†…å®¹ã€‚å¦‚æœæ‚¨æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ä½œä¸ºä¸€ä¸ªæ–‡æœ¬äº¤äº’çš„AIï¼Œæˆ‘å¯ä»¥å›é¡¾æˆ‘ä»¬çš„å¯¹è¯è®°å½•ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„å¯¹è¯å†…å®¹å¦‚ä¸‹ï¼š\\n\\n1. æ‚¨é—®æˆ‘ï¼šâ€œæˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿâ€\\n2. æˆ‘å›ç­”è¯´ï¼Œä½œä¸ºAIï¼Œæˆ‘æ²¡æœ‰è®¿é—®æ‚¨ä¸ªäººä¿¡æ¯çš„æƒé™ï¼Œæ‰€ä»¥æˆ‘ä¸çŸ¥é“æ‚¨çš„åå­—ï¼Œå¹¶æå‡ºå¦‚æœæ‚¨æ„¿æ„å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šçŸ¥é“å¦‚ä½•ç§°å‘¼æ‚¨ã€‚\\n\\nè¿™å°±æ˜¯æˆ‘ä»¬ç›®å‰ä¸ºæ­¢çš„å…¨éƒ¨å¯¹è¯å†…å®¹ã€‚å¦‚æœæ‚¨æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"å¥½å‰å®³ï¼Œåˆšæ‰æˆ‘ä»¬éƒ½èŠäº†ä»€ä¹ˆï¼Ÿ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
