{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"deepseek.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "api_base = os.getenv(\"DEEPSEEK_API_BASE\")\n",
    "serp_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base\n",
    "os.environ[\"SERPAPI_API_KEY\"] =serp_api_key\n",
    "# 为 DeepSeek 配置（可选）\n",
    "DEEPSEEK_CONFIG = {\n",
    "    #\"model\": \"gpt-3.5-turbo\",  # 或者使用 DeepSeek 兼容模型\n",
    "    #\"openai_api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    # 如果使用 DeepSeek:\n",
    "    \"model\": \"deepseek-chat\",\n",
    "    \"openai_api_base\": os.environ[\"DEEPSEEK_API_BASE\"],\n",
    "    \"openai_api_key\": os.environ[\"DEEPSEEK_API_KEY\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何给agent正确的增加记忆\n",
    "\n",
    "- 将memory插入到提示词模板中\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.prompts import  MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/1534123048.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm=ChatOpenAI(\n",
    "    temperature=0,\n",
    "    **DEEPSEEK_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建agent可用工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='Search', description='useful for when you need to answer questions about current events or the current state of the world', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='54593553f44d1d9c8c2e610beaf57d8de0fe6c25fce97628e591ef64f5ddad04', aiosession=None)>), Tool(name='Calculator', description='useful for when you need to answer questions about math', func=<bound method Chain.run of LLMMathChain(verbose=True, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x136a31850>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1374aa9f0>, model_name='deepseek-chat', temperature=0.0, model_kwargs={}, openai_api_key='sk-1719a446a8a643d8ba71d7b4cee55069', openai_api_base='https://api.deepseek.com/v1', openai_proxy=''), output_parser=StrOutputParser(), llm_kwargs={}), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x136a31850>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1374aa9f0>, model_name='deepseek-chat', temperature=0.0, model_kwargs={}, openai_api_key='sk-1719a446a8a643d8ba71d7b4cee55069', openai_api_base='https://api.deepseek.com/v1', openai_proxy=''))>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/3294897194.py:4: LangChainDeprecationWarning: This class is deprecated and will be removed in langchain 1.0. See API reference for replacement: https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_math.base.LLMMathChain.html\n",
      "  llm_math_chain = LLMMathChain(\n",
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/3294897194.py:4: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  llm_math_chain = LLMMathChain(\n"
     ]
    }
   ],
   "source": [
    "#构建一个搜索工具\n",
    "search = SerpAPIWrapper()\n",
    "#创建一个数学计算工具\n",
    "llm_math_chain = LLMMathChain(\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events or the current state of the world\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "]\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加memory组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/1205651814.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/1ywp7kxn5c7gc6h0spb3v9vm0000gn/T/ipykernel_64512/1161536941.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_chain = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.OPENAI_FUNCTIONS, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True,#处理解析错误\n",
    "    memory=memory #记忆组件\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看默认的agents prompt是什么样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI assistant.', additional_kwargs={}, response_metadata={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "content='You are a helpful AI assistant.' additional_kwargs={} response_metadata={}\n",
      "prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}') additional_kwargs={}\n",
      "variable_name='agent_scratchpad'\n"
     ]
    }
   ],
   "source": [
    "print(agent_chain.agent.prompt.messages)\n",
    "print(agent_chain.agent.prompt.messages[0])\n",
    "print(agent_chain.agent.prompt.messages[1])\n",
    "print(agent_chain.agent.prompt.messages[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你好，李晨！很高兴认识你。如果你有任何问题或需要帮助的地方，请随时告诉我，我会尽力为你提供支持。祝你今天一切顺利！ 😊\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m目前我无法知道你的名字，因为你还没有告诉我！😊 但如果你愿意告诉我，我会记住并在接下来的对话中使用它。或者，你可以直接告诉我你想让我怎么称呼你～ 你希望我怎么称呼你呢？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'目前我无法知道你的名字，因为你还没有告诉我！😊 但如果你愿意告诉我，我会记住并在接下来的对话中使用它。或者，你可以直接告诉我你想让我怎么称呼你～ 你希望我怎么称呼你呢？'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"我叫什么名字？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要使用agent_kwargs传递参数，将chat_history传入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.OPENAI_FUNCTIONS, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True,#处理解析错误\n",
    "    agent_kwargs={\n",
    "        \"extra_prompt_messages\":[MessagesPlaceholder(variable_name=\"chat_history\"),MessagesPlaceholder(variable_name=\"agent_scratchpad\")],\n",
    "    },\n",
    "    memory=memory #记忆组件\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看重新渲染后的提示词模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI assistant.', additional_kwargs={}, response_metadata={}), MessagesPlaceholder(variable_name='chat_history'), MessagesPlaceholder(variable_name='agent_scratchpad'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "content='You are a helpful AI assistant.' additional_kwargs={} response_metadata={}\n",
      "variable_name='chat_history'\n",
      "variable_name='agent_scratchpad'\n"
     ]
    }
   ],
   "source": [
    "print(agent_chain.agent.prompt.messages)\n",
    "print(agent_chain.agent.prompt.messages[0])\n",
    "print(agent_chain.agent.prompt.messages[1])\n",
    "print(agent_chain.agent.prompt.messages[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m作为一个文本交互的AI，我可以回顾我们的对话记录。到目前为止，我们的对话内容如下：\n",
      "\n",
      "1. 您问我：“我叫什么名字？”\n",
      "2. 我回答说，作为AI，我没有访问您个人信息的权限，所以我不知道您的名字，并提出如果您愿意告诉我，我会知道如何称呼您。\n",
      "\n",
      "这就是我们目前为止的全部对话内容。如果您有其他问题或需要帮助，请随时告诉我！\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'作为一个文本交互的AI，我可以回顾我们的对话记录。到目前为止，我们的对话内容如下：\\n\\n1. 您问我：“我叫什么名字？”\\n2. 我回答说，作为AI，我没有访问您个人信息的权限，所以我不知道您的名字，并提出如果您愿意告诉我，我会知道如何称呼您。\\n\\n这就是我们目前为止的全部对话内容。如果您有其他问题或需要帮助，请随时告诉我！'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"好厉害，刚才我们都聊了什么？\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
